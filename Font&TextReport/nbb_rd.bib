Automatically generated by Mendeley Desktop 1.19.8
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop


@ARTICLE{8169670,
  author={Lin, Sangdi and Runger, George C.},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={GCRNN: Group-Constrained Convolutional Recurrent Neural Network}, 
  year={2018},
  volume={29},
  number={10},
  pages={4709-4718},
  doi={10.1109/TNNLS.2017.2772336}}
@misc{yousef2020origaminet,
      title={OrigamiNet: Weakly-Supervised, Segmentation-Free, One-Step, Full Page Text Recognition by learning to unfold}, 
      author={Mohamed Yousef and Tom E. Bishop},
      year={2020},
      eprint={2006.07491},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@incollection{NEURIPS2019_9015,
title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
pages = {8024--8035},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf}
}
@article{SAUVOLA2000225,
title = {Adaptive document image binarization},
journal = {Pattern Recognition},
volume = {33},
number = {2},
pages = {225-236},
year = {2000},
issn = {0031-3203},
doi = {https://doi.org/10.1016/S0031-3203(99)00055-2},
url = {https://www.sciencedirect.com/science/article/pii/S0031320399000552},
author = {J. Sauvola and M. Pietikäinen},
keywords = {Adaptive binarization, Soft decision, Document segmentation, Document analysis, Document understanding},
abstract = {A new method is presented for adaptive document image binarization, where the page is considered as a collection of subcomponents such as text, background and picture. The problems caused by noise, illumination and many source type-related degradations are addressed. Two new algorithms are applied to determine a local threshold for each pixel. The performance evaluation of the algorithm utilizes test images with ground-truth, evaluation metrics for binarization of textual and synthetic images, and a weight-based ranking procedure for the final result presentation. The proposed algorithms were tested with images including different types of document components and degradations. The results were compared with a number of known techniques in the literature. The benchmarking results show that the method adapts and performs well in each case qualitatively and quantitatively.}
}
@inproceedings{inproceedings,
author = {Graves, Alex and Fernández, Santiago and Gomez, Faustino and Schmidhuber, Jürgen},
year = {2006},
month = {01},
pages = {369-376},
title = {Connectionist temporal classification: Labelling unsegmented sequence data with recurrent neural 'networks},
volume = {2006},
journal = {ICML 2006 - Proceedings of the 23rd International Conference on Machine Learning},
doi = {10.1145/1143844.1143891}
}
@misc{loshchilov2019decoupled,
      title={Decoupled Weight Decay Regularization}, 
      author={Ilya Loshchilov and Frank Hutter},
      year={2019},
      eprint={1711.05101},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{oktay2018attention,
      title={Attention U-Net: Learning Where to Look for the Pancreas}, 
      author={Ozan Oktay and Jo Schlemper and Loic Le Folgoc and Matthew Lee and Mattias Heinrich and Kazunari Misawa and Kensaku Mori and Steven McDonagh and Nils Y Hammerla and Bernhard Kainz and Ben Glocker and Daniel Rueckert},
      year={2018},
      eprint={1804.03999},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@misc{milletari2016vnet,
      title={V-Net: Fully Convolutional Neural Networks for Volumetric Medical Image Segmentation}, 
      author={Fausto Milletari and Nassir Navab and Seyed-Ahmad Ahmadi},
      year={2016},
      eprint={1606.04797},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@misc{vaswani2017attention,
      title={Attention Is All You Need}, 
      author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
      year={2017},
      eprint={1706.03762},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{smith2017cyclical,
      title={Cyclical Learning Rates for Training Neural Networks}, 
      author={Leslie N. Smith},
      year={2017},
      eprint={1506.01186},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{faucris.276690551,
     abstract = {Automatically extracting targeted information from historical documents is an important task in the field of document analysis and eases the work of historians when dealing with huge corpora. In this work, we investigate the idea of retrieving the recipient transcriptions from the Nuremberg letterbooks of the 15th century. This task can be solved with fundamentally different ways of approaching it. First, detecting recipient lines solely based on visual features and without any explicit linguistic feedback. Here, we use a vanilla U-Net and an attention-based U-Net as representatives. Second, linguistic feedback can be used to classify each line accordingly. This is done on the one hand with handwritten text recognition (HTR) for predicting the transcriptions and on top of it a light-wight natural language processing (NLP) model distinguishing whether the line is a recipient line or not. On the other hand, we adapt a named entity recognition transformer model. The system jointly performs the line transcription and the recipient line recognition. For improving the performance, we investigated all the possible combinations with the different methods. In most cases the combined output probabilities outperformed the single approaches. The best combination achieved on the hard test set an F1 score of 80% and recipient line recognition accuracy of about 96% while the best single approach only reached about 74% and 94%, respectively.},
     author = {Mayr, Martin and Felker, Alex and Maier, Andreas and Christlein, Vincent},
     booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
     date = {2022-05-22/2022-05-25},
     doi = {10.1007/978-3-031-06555-2{\_}40},
     editor = {Seiichi Uchida, Elisa Barney, Véronique Eglin},
     faupublication = {yes},
     isbn = {9783031065545},
     keywords = {Handwritten text recognition; Natural language processing; Recipient recognition; Semantic image segmentation},
     note = {CRIS-Team Scopus Importer:2022-06-10},
     pages = {598-612},
     peerreviewed = {unknown},
     publisher = {Springer Science and Business Media Deutschland GmbH},
     title = {{Combining} {Visual} and {Linguistic} {Models} for a {Robust} {Recipient} {Line} {Recognition} in {Historical} {Documents}},
     venue = {La Rochelle, FRA},
     volume = {13237 LNCS},
     year = {2022}
}
@misc{lee2019recognizing,
      title={On Recognizing Texts of Arbitrary Shapes with 2D Self-Attention}, 
      author={Junyeop Lee and Sungrae Park and Jeonghun Baek and Seong Joon Oh and Seonghyeon Kim and Hwalsuk Lee},
      year={2019},
      eprint={1910.04396},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{faucris.312972480,
 abstract = {In this paper, we investigate the usage of fine-grained font recognition on OCR for books printed from the 15th to the 18th century. We used a newly created dataset for OCR of early printed books for which fonts are labeled with bounding boxes. We know not only the font group used for each character, but the locations of font changes as well. In books of this period, we frequently find font group changes mid-line or even mid-word that indicate changes in language. We consider 8 different font groups present in our corpus and investigate 13 different subsets: the whole dataset and text lines with a single font, multiple fonts, Roman fonts, Gothic fonts, and each of the considered fonts, respectively. We show that OCR performance is strongly impacted by font style and that selecting fine-tuned models with font group recognition has a very positive impact on the results. Moreover, we developed a system using local font group recognition in order to combine the output of multiple font recognition models, and show that while slower, this approach performs better not only on text lines composed of multiple fonts but on the ones containing a single font only as well.},
 address = {Cham},
 author = {Seuret, Mathias and van der Loop, Janne and Weichselbaumer, Nikolaus and Mayr, Martin and Molnar, Janina and Hass, Tatjana and Christlein, Vincent},
 booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
 date = {2023-08-21/2023-08-26},
 doi = {10.1007/978-3-031-41734-4{\_}21},
 editor = {Gernot A. Fink, Rajiv Jain, Koichi Kise, Richard Zanibbi},
 faupublication = {yes},
 isbn = {9783031417337},
 keywords = {Early modern prints; Historical documents; OCR},
 note = {CRIS-Team Scopus Importer:2023-10-20},
 pages = {342-357},
 peerreviewed = {unknown},
 publisher = {Springer Science and Business Media Deutschland GmbH},
 title = {{Combining} {OCR} {Models} for {Reading} {Early} {Modern} {Books}},
 venue = {San José, CA},
 volume = {14191 LNCS},
 year = {2023}
}

@misc{rouhoua2021transformerbased,
      title={Transformer-Based Approach for Joint Handwriting and Named Entity Recognition in Historical documents}, 
      author={Ahmed Cheikh Rouhoua and Marwa Dhiaf and Yousri Kessentini and Sinda Ben Salem},
      year={2021},
      eprint={2112.04189},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@INPROCEEDINGS{7780459,
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Deep Residual Learning for Image Recognition}, 
  year={2016},
  volume={},
  number={},
  pages={770-778},
  keywords={Training;Degradation;Complexity theory;Image recognition;Neural networks;Visualization;Image segmentation},
  doi={10.1109/CVPR.2016.90}}



